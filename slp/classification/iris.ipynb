{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Classification using La Classy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDownloading\u001b[39m https://github.com/retraigo/classy-lala/releases/download/v0.7.0/classy.dll\n"
     ]
    }
   ],
   "source": [
    "import { parse } from \"https://deno.land/std@0.204.0/csv/parse.ts\";\n",
    "import {\n",
    "  ClassificationReport,\n",
    "  Matrix,\n",
    "  useSplit,\n",
    "  CategoricalEncoder,\n",
    "} from \"https://deno.land/x/vectorizer@v0.3.4/mod.ts\";\n",
    "import {\n",
    "  GradientDescentSolver,\n",
    "  softmaxActivation,\n",
    "  adamOptimizer,\n",
    "  crossEntropy,\n",
    "} from \"https://deno.land/x/classylala@v0.7.0/src/mod.ts\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load our dataset `iris.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const data = parse(Deno.readTextFileSync(\"../../datasets/iris.csv\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the predictor and target variables from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "const X = new Matrix<\"f64\">(Float64Array, [data.length, 4]);\n",
    "data.forEach((fl, i) => X.setRow(i, fl.slice(0, 4).map(Number)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  \u001b[32m\"Species\"\u001b[39m,    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "  \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "  ... 51 more items\n",
       "]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const y_pre = data.map((fl) => fl[4]);\n",
    "y_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variables are all strings. In order to use them for classification, we convert them into categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th>idx</th><th>0</th><th>1</th><th>2</th><th>3</th></tr></thead><tr><td><strong>0</strong></td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td><strong>1</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>2</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>3</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>4</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>5</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>6</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>7</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>8</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>9</strong></td><td>0</td><td>1</td><td>0</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "1\t0\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n",
       "0\t1\t0\t0\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const encoder = new CategoricalEncoder()\n",
    "const y = encoder.fit(y_pre).transform<\"f64\">(y_pre, \"f64\")\n",
    "y.slice(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ [ \u001b[33m151\u001b[39m, \u001b[33m4\u001b[39m ], [ \u001b[33m151\u001b[39m, \u001b[33m4\u001b[39m ] ]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X.shape, y.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our dataset for training and testing purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th>idx</th><th>0</th><th>1</th><th>2</th><th>3</th></tr></thead><tr><td><strong>0</strong></td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><td><strong>1</strong></td><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td></tr><tr><td><strong>2</strong></td><td>4.9</td><td>3</td><td>1.4</td><td>0.2</td></tr><tr><td><strong>3</strong></td><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td></tr><tr><td><strong>4</strong></td><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td></tr><tr><td><strong>5</strong></td><td>5</td><td>3.6</td><td>1.4</td><td>0.2</td></tr><tr><td><strong>6</strong></td><td>5.4</td><td>3.9</td><td>1.7</td><td>0.4</td></tr><tr><td><strong>7</strong></td><td>5</td><td>3.4</td><td>1.5</td><td>0.2</td></tr><tr><td><strong>8</strong></td><td>4.9</td><td>3.1</td><td>1.5</td><td>0.1</td></tr><tr><td><strong>9</strong></td><td>5.4</td><td>3.7</td><td>1.5</td><td>0.2</td></tr></table>"
      ],
      "text/plain": [
       "NaN\tNaN\tNaN\tNaN\n",
       "5.1\t3.5\t1.4\t0.2\n",
       "4.9\t3\t1.4\t0.2\n",
       "4.7\t3.2\t1.3\t0.2\n",
       "4.6\t3.1\t1.5\t0.2\n",
       "5\t3.6\t1.4\t0.2\n",
       "5.4\t3.9\t1.7\t0.4\n",
       "5\t3.4\t1.5\t0.2\n",
       "4.9\t3.1\t1.5\t0.1\n",
       "5.4\t3.7\t1.5\t0.2\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const [[x_train, y_train], [x_test, y_test]] = useSplit(\n",
    "  { ratio: [7, 3], shuffle: true },\n",
    "  X,\n",
    "  y\n",
    ");\n",
    "x_train.slice(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared our inputs, we can initialize our solver. Since we are performing logistic regression, we use a Gradient Descent solver.\n",
    "\n",
    "We use the `crossEntropy` loss function which is used for multinomial classification, `adam` as our optimizer, and finally a `softmax` function to compute joint probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "const solver = new GradientDescentSolver({\n",
    "  loss: crossEntropy(),\n",
    "  activation: softmaxActivation(),\n",
    "  optimizer: adamOptimizer(4, 3),\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train our model using the data we acquired.\n",
    "\n",
    "Setting the learning rate to a small value is desirable. Since our dataset is pretty simple, we are training our model for 300 epochs with 20 minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "solver.train(x_train, y_train, {\n",
    "  learning_rate: 0.01,\n",
    "  epochs: 300,\n",
    "  n_batches: 20,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained, now it is time to evaluate its performance on our testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ \u001b[33m45\u001b[39m, \u001b[33m3\u001b[39m ]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const res = solver.predict(x_test)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Array(3) [\n",
       "  \u001b[33m0.9999983187768419\u001b[39m,\n",
       "  \u001b[33m0.00000168122087255425\u001b[39m,\n",
       "  \u001b[33m2.2855526070298736e-12\u001b[39m\n",
       "]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.row(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function provides probabilities for the data point to belong to each of the classes. In our case, the three numbers in the array represent the probabilities of the first data point belonging to the classes `setosa`, `versicolor`, and `virginica` respectively.\n",
    "\n",
    "We convert these into one-hot representations by taking the `argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th>idx</th><th>0</th><th>1</th><th>2</th></tr></thead><tr><td><strong>0</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>1</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>2</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>3</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>4</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>5</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>6</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>7</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>8</strong></td><td>1</td><td>0</td><td>0</td></tr><tr><td><strong>9</strong></td><td>1</td><td>0</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n",
       "1\t0\t0\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let i = 0;\n",
    "for (const row of res.rows()) {\n",
    "  const max = row.reduce((acc, curr, i, arr) => arr[acc] > curr ? acc : i, 0)\n",
    "  const newR = new Array(row.length).fill(0)\n",
    "  newR[max] = 1\n",
    "  res.setRow(i, newR)\n",
    "  i += 1;\n",
    "}\n",
    "res.slice(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our encoder to convert the categorical variables into class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const y_pred = encoder.untransform(res)\n",
    "const y_act = encoder.untransform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m\n",
       "  ],\n",
       "  [\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,\n",
       "    \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"setosa\"\u001b[39m,     \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m,\n",
       "    \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"versicolor\"\u001b[39m, \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,\n",
       "    \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m,  \u001b[32m\"virginica\"\u001b[39m\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_pred, y_act]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can generate a classification report based on our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>Class</th><th>Precision</th><th>F1Score</th><th>Recall</th><th>Support</th></tr></thead><tr><td>Class setosa</td><td>1</td><td>1</td><td>1</td><td>17</td></tr><tr><td>Class versicolor</td><td>1</td><td>1</td><td>1</td><td>12</td></tr><tr><td>Class virginica</td><td>1</td><td>1</td><td>1</td><td>16</td></tr><tr><td>Accuracy</td><td></td><td>1</td><td>45</td></tr></table>"
      ],
      "text/plain": [
       "Classification Report\n",
       "Number of classes:\t3\n",
       "Class\tPreci\tF1\tRec\tSup\n",
       "setosa\t1\t1\t1\t17\n",
       "versicolor\t1\t1\t1\t12\n",
       "virginica\t1\t1\t1\t16\n",
       "Accuracy\t\t1\t45"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new ClassificationReport(y_act, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the classifier easily classifies different iris species. This is possible because the classes are easily separable. In a more complex database, these results may greatly vary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
